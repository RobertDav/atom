1.kafkaProducer 相当于收件员
  首先对消息进行加工 如序列化 选择分区
  (1)拦截器处理(对快递进行发送前的预处理)
  (2)判断producer是否可用 依据是负责IO的线程是否工作(车队是否罢工)
  (3)判断metadata是否可用。meta相当于调度员的指挥图，存储了kafka集群的各种信息 包括topic 分区等信息(类似与快递站的网点信息)
  (4)对key value 进行序列化 (对快递进行包装)
  (5)获取要发往的分区编号(快递目的地部分地址)
  (6)计算序列化后的大小(快件称重)
2.RecordAccumulator相当于分拣员，负责将消息按照分区分类 放入到相对应的ProducerBatch
  ProducerBatch 每个ProducerBatch是一个信箱 而同一个partition的信箱码放在一起 在程序中表现 Deque<ProducerBatch>
  当batch满是触发sender线程 sender线程首先把batch从原列表中取出来按照发往broker进行分组然后封装到ClientRequest中
  (7)通过RecordAccumulator 把消息加入到batch中(分拣员进行分拣)
    同时又一个业务主线程 与 sender线程操作recordAccumulator 所以recordAccumulator 是线程安全的
    RecordAccumulator实现了接受消息，ConcurrentMap<TopicPartition, Deque<ProducerBatch>> 然后以主题分区为单元，把消息以producerBatch为单位累计缓存，多个producerBatch保存在Deque队列中
    当Deque中最新的batch已不能容纳消息时，就会创建新的Batch来继续缓存并将其加入到Deque中
    消息真实存放在dataOutPutStream ProducerBatch内部又一个memoryRecordBuilder对象 ProducerBatch->memoryRecordBuilder->dataOutPutStream
    RecordAccumulator 消息累积器的顶层逻辑，维护存放消息的容器
    ProducerBatch 封装memoryRecordBuilder 并且有很多控制用的信息以及统计信息
    MemberRecordBuilder 消息真正累积存放的地方
    总结
    7.1 recordAccumulator 使用producerBatch来缓存消息 每个topicPartition都拥有一个Deque<ProducerBatch> ConcurrentMap<TopicPartition, Deque<ProducerBatch>>
    7.2 当producerBatch 队列的队尾不能容纳新的消息时对其进行封箱 同时新建ProducerBatch放到队尾来接受新的消息
    7.3 ProducerBatch 对消息的追加操作都是通过MemoryRecordBuilder进行的 消息最终被追加到MemoryRecordBuilder 中的dataOutPutStream appendStream 中
3.Sender 相当于运输车 负责将消息真正发送出去 通过NIO实现网络传输
  clientRequest 可以理解成运输车的货箱 在运输之前 我们会把发往同一个服务器的消息存入到clientRequest ，那么只需要
  发送一此clientRequest 就可以把不同主题不同分区，但发往同一服务器的消息一次性发过去
  (8)如果batch满了 或者创建了新batch来容纳消息，则唤醒sender线程执行发送(已经有封箱的货物 可以发货了)






1.创建producerRecord 对象 此对象中包含 topic，以及发送的内容，还可以指定键或者分区
2.生产者对producerRecord 对象进行序列化
3.分区器接收到消息后 先来选择一个分区
4.这条记录被添加到recordAccumulator 这个批次会被发送到相同的主题和分区上
5.sender线程负责将这些记录批次 发送到相对应的broker上
6.broker 在接受到消息时 会返回一个响应，如果成功返回一个recordMeraData 包含主题和 分区西悉尼，以及记录在分区的偏移量
7.生产者如果接收到错误会尝试发送
https://img-blog.csdnimg.cn/20200504085326693.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExMjQwNDY2MTk2,size_16,color_FFFFFF,t_70
消息发送分为 3个模块
  1.主线程负责 生产消息 并序列化，选择分区，然后将消息存放到recordAccumulator中，相当于缓冲区，
    producerInterceptor 在消息被序列化之前对消息内送进行修改onSend()，也可以在消息应答或者消息发送失败时做处理onAcknowledgement()会先于用户自定义的回调方法 这个是运行在I/O线程中 不要搞太多逻辑
    Serializer 对消息的key和value 进行序列化
    partitioner 为消息选择合适的partition
    recordAccumulator 收集消息 实现批量发送
  2.当缓冲区满了之后 sender线程会从缓冲区中读取数据
    sender线程从recordAccumulator中收集消息 实现批量发送
    构造 clientRequest
    将clientRequest交给netWorkClient准备发送
    networkClient 将请求放入kafkaChannel
  3.发送到相对应的broker上
    执行网络IO 发送请求
    收到响应调用clientRequest的回调函数
    调用recordBatch的回调函数，最终调用每个消息上注册的回调函数
集群元数据
  在KafkaProducer 中 使用Node,TopicPartition,PartitionInfo封装了Kafka集群相关的元数据
  Node:表示集群中的一个节点，Node记录了这个节点的host，IP，port等信息
  TopicPatition：表示某Topic的一个分区，其中topic字段是Topic的名称，partitioner字段则是此分区在Topic中的分区编号（ID）
  partitionInfo:分区的详细信息，leader 字段记录了Leader 副本所在节点的id，replica字段记录了全部副本所在的节点信息，inSyncReplicas 字段记录了ISR
  集合中所有副本所在的信息
